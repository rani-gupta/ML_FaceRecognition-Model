{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 ZeroPadding2D True\n",
      "2 Conv2D True\n",
      "3 BatchNormalization True\n",
      "4 ReLU True\n",
      "5 DepthwiseConv2D True\n",
      "6 BatchNormalization True\n",
      "7 ReLU True\n",
      "8 Conv2D True\n",
      "9 BatchNormalization True\n",
      "10 ReLU True\n",
      "11 ZeroPadding2D True\n",
      "12 DepthwiseConv2D True\n",
      "13 BatchNormalization True\n",
      "14 ReLU True\n",
      "15 Conv2D True\n",
      "16 BatchNormalization True\n",
      "17 ReLU True\n",
      "18 DepthwiseConv2D True\n",
      "19 BatchNormalization True\n",
      "20 ReLU True\n",
      "21 Conv2D True\n",
      "22 BatchNormalization True\n",
      "23 ReLU True\n",
      "24 ZeroPadding2D True\n",
      "25 DepthwiseConv2D True\n",
      "26 BatchNormalization True\n",
      "27 ReLU True\n",
      "28 Conv2D True\n",
      "29 BatchNormalization True\n",
      "30 ReLU True\n",
      "31 DepthwiseConv2D True\n",
      "32 BatchNormalization True\n",
      "33 ReLU True\n",
      "34 Conv2D True\n",
      "35 BatchNormalization True\n",
      "36 ReLU True\n",
      "37 ZeroPadding2D True\n",
      "38 DepthwiseConv2D True\n",
      "39 BatchNormalization True\n",
      "40 ReLU True\n",
      "41 Conv2D True\n",
      "42 BatchNormalization True\n",
      "43 ReLU True\n",
      "44 DepthwiseConv2D True\n",
      "45 BatchNormalization True\n",
      "46 ReLU True\n",
      "47 Conv2D True\n",
      "48 BatchNormalization True\n",
      "49 ReLU True\n",
      "50 DepthwiseConv2D True\n",
      "51 BatchNormalization True\n",
      "52 ReLU True\n",
      "53 Conv2D True\n",
      "54 BatchNormalization True\n",
      "55 ReLU True\n",
      "56 DepthwiseConv2D True\n",
      "57 BatchNormalization True\n",
      "58 ReLU True\n",
      "59 Conv2D True\n",
      "60 BatchNormalization True\n",
      "61 ReLU True\n",
      "62 DepthwiseConv2D True\n",
      "63 BatchNormalization True\n",
      "64 ReLU True\n",
      "65 Conv2D True\n",
      "66 BatchNormalization True\n",
      "67 ReLU True\n",
      "68 DepthwiseConv2D True\n",
      "69 BatchNormalization True\n",
      "70 ReLU True\n",
      "71 Conv2D True\n",
      "72 BatchNormalization True\n",
      "73 ReLU True\n",
      "74 ZeroPadding2D True\n",
      "75 DepthwiseConv2D True\n",
      "76 BatchNormalization True\n",
      "77 ReLU True\n",
      "78 Conv2D True\n",
      "79 BatchNormalization True\n",
      "80 ReLU True\n",
      "81 DepthwiseConv2D True\n",
      "82 BatchNormalization True\n",
      "83 ReLU True\n",
      "84 Conv2D True\n",
      "85 BatchNormalization True\n",
      "86 ReLU True\n",
      "Found 100 images belonging to 1 classes.\n",
      "Found 60 images belonging to 1 classes.\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 232s 3s/step - loss: 0.0112 - accuracy: 0.9904 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n",
      "Class - rani\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "#Load the MobileNet model\n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224  \n",
    "model = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "#for printing  layers of the model\n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "\n",
    "#shows the trainable layers\n",
    "\n",
    "model.layers[0].trainable\n",
    "\n",
    "\n",
    "model.output\n",
    "# to Freez the layers(important line)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "#Storing the output layer in a variable\n",
    "\n",
    "model_output = model.output\n",
    "\n",
    "model_output = Flatten()(model_output)\n",
    "\n",
    "#for adding extra layers\n",
    "\n",
    "model_output = Dense(units = 512 , activation='relu' )(model_output)\n",
    "model_output = Dense(units= 256, activation='relu' )(model_output)\n",
    "model_output = Dense(units= 1 , activation='sigmoid' )(model_output)\n",
    "\n",
    "\n",
    "#shows the input and output layers\n",
    "\n",
    "model= Model(inputs=model.input , outputs = model_output)\n",
    "\n",
    "#compile the model\n",
    "\n",
    "model.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "#for training the model after augementation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'C:/Users/Dell/Desktop/mloops/Images/train/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'C:/Users/Dell/Desktop/mloops/Images/validation/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "model.fit(\n",
    "        training_set,\n",
    "        steps_per_epoch=70,\n",
    "        epochs=1,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for Saving and loading the model\n",
    "\n",
    "model.save('face_recog_mobilenet.h5')\n",
    "from keras.models import load_model\n",
    "classifier = load_model('face_recog_mobilenet.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#to Predict the Random Images using face recognization model\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "human_dict = {\"[0]\": \"rani\" \n",
    "              }\n",
    "\n",
    "human_dict_n = {\"rani\": \"rani\"\n",
    "                }\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    human = human_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, human, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + human_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"C:/Users/Dell/Desktop/mloops/Images/validation/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # to Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
